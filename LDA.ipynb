{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "305b0a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b44f0e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Fatima\n",
      "[nltk_data]     Dy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "20eb23e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "                                              review  sentiment\n",
      "0  at first gumagana cya..pero pagnalowbat cya nd...          1\n",
      "1  grabi pangalawa ko ng order sa shapee pero pur...          1\n",
      "2  2l gray/black order ko. bakit 850ml lang po pi...          1\n",
      "3  walang silbing product.. bwesit. di gumagana d...          1\n",
      "4  d po maganda naman po yung neck fan, pero po n...          4\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('dataset/SentiTaglish_ProductsAndServices.csv')\n",
    "print(\"Original dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "04ac2df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review\n",
      "0  at first gumagana cya..pero pagnalowbat cya nd...\n",
      "1  grabi pangalawa ko ng order sa shapee pero pur...\n",
      "2  2l gray/black order ko. bakit 850ml lang po pi...\n",
      "3  walang silbing product.. bwesit. di gumagana d...\n",
      "4  d po maganda naman po yung neck fan, pero po n...\n"
     ]
    }
   ],
   "source": [
    "# Drop the sentiment column\n",
    "reviews_df = df.drop(columns=['sentiment'])\n",
    "print(reviews_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4ec261ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = reviews_df['review'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "001e98d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tagalog stopwords function\n",
    "def load_stopwords(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        return set(line.strip() for line in file if line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e67728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stopwords\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "# Tagalog/Filipino stopwords \n",
    "tagalog_stopwords = load_stopwords(\"stopwords-tl.txt\")\n",
    "\n",
    "combined_stopwords = set(english_stopwords).union(tagalog_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "215e29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_data(documents):\n",
    "    return [\n",
    "        [word for word in simple_preprocess(str(doc)) if word not in combined_stopwords]\n",
    "        for doc in documents\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b3c0885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the documents\n",
    "processed_texts = preprocess_data(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0bfd68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary and corpus\n",
    "id2word = corpora.Dictionary(processed_texts)\n",
    "corpus = [id2word.doc2bow(text) for text in processed_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a38676bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train the LDA model\n",
    "num_topics = 10\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=num_topics,\n",
    "    random_state=42,\n",
    "    passes=10,\n",
    "    alpha='auto',\n",
    "    per_word_topics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "195f2b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics found by LDA:\n",
      "[(0,\n",
      "  '0.036*\"godbless\" + 0.030*\"overall\" + 0.021*\"arrived\" + 0.016*\"mystery\" + '\n",
      "  '0.016*\"immediately\" + 0.013*\"mejo\" + 0.013*\"pouch\" + 0.012*\"mouse\" + '\n",
      "  '0.011*\"better\" + 0.009*\"ty\"'),\n",
      " (1,\n",
      "  '0.054*\"size\" + 0.044*\"order\" + 0.031*\"yung\" + 0.029*\"kaso\" + 0.029*\"color\" '\n",
      "  '+ 0.029*\"dumating\" + 0.021*\"maliit\" + 0.020*\"black\" + 0.017*\"kulay\" + '\n",
      "  '0.016*\"mali\"'),\n",
      " (2,\n",
      "  '0.018*\"pink\" + 0.018*\"kulay\" + 0.017*\"dumating\" + 0.016*\"order\" + '\n",
      "  '0.014*\"kaso\" + 0.013*\"color\" + 0.013*\"blue\" + 0.010*\"inorder\" + 0.009*\"nag\" '\n",
      "  '+ 0.009*\"mag\"'),\n",
      " (3,\n",
      "  '0.086*\"yung\" + 0.030*\"kaso\" + 0.020*\"item\" + 0.017*\"kasi\" + 0.014*\"maganda\" '\n",
      "  '+ 0.013*\"wala\" + 0.012*\"pag\" + 0.010*\"nung\" + 0.010*\"nya\" + 0.009*\"parang\"'),\n",
      " (4,\n",
      "  '0.061*\"thank\" + 0.050*\"maganda\" + 0.048*\"seller\" + 0.046*\"good\" + '\n",
      "  '0.036*\"quality\" + 0.030*\"price\" + 0.021*\"nice\" + 0.018*\"tela\" + '\n",
      "  '0.016*\"medyo\" + 0.015*\"nya\"'),\n",
      " (5,\n",
      "  '0.028*\"uulitin\" + 0.013*\"staff\" + 0.013*\"tumagal\" + 0.009*\"jogging\" + '\n",
      "  '0.009*\"kapal\" + 0.009*\"service\" + 0.008*\"hotel\" + 0.008*\"lakas\" + '\n",
      "  '0.007*\"compared\" + 0.006*\"week\"'),\n",
      " (6,\n",
      "  '0.059*\"order\" + 0.051*\"seller\" + 0.034*\"thank\" + 0.030*\"shop\" + '\n",
      "  '0.028*\"time\" + 0.026*\"complete\" + 0.023*\"items\" + 0.019*\"dumating\" + '\n",
      "  '0.018*\"good\" + 0.018*\"sulit\"'),\n",
      " (7,\n",
      "  '0.101*\"ganda\" + 0.082*\"super\" + 0.030*\"sobrang\" + 0.025*\"quality\" + '\n",
      "  '0.025*\"talaga\" + 0.018*\"affordable\" + 0.017*\"thank\" + 0.017*\"worth\" + '\n",
      "  '0.011*\"price\" + 0.011*\"mura\"'),\n",
      " (8,\n",
      "  '0.038*\"love\" + 0.034*\"amoy\" + 0.014*\"related\" + 0.012*\"long\" + '\n",
      "  '0.011*\"mainit\" + 0.011*\"mabango\" + 0.011*\"surely\" + 0.010*\"bet\" + '\n",
      "  '0.009*\"video\" + 0.009*\"like\"'),\n",
      " (9,\n",
      "  '0.180*\"po\" + 0.044*\"seller\" + 0.034*\"order\" + 0.034*\"thank\" + 0.024*\"ganda\" '\n",
      "  '+ 0.022*\"ulit\" + 0.018*\"maganda\" + 0.015*\"thankyou\" + 0.014*\"thanks\" + '\n",
      "  '0.013*\"rider\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the topics\n",
    "print(\"\\nTopics found by LDA:\")\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "062303dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score: 0.4606332724074339\n"
     ]
    }
   ],
   "source": [
    "# Compute coherence score\n",
    "coherence_model_lda = CoherenceModel(\n",
    "    model=lda_model,\n",
    "    texts=processed_texts,\n",
    "    dictionary=id2word,\n",
    "    coherence='c_v'\n",
    ")\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score:', coherence_lda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
