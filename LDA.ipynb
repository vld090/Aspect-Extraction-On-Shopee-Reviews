{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "305b0a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b44f0e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vldth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20eb23e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "                                              review  sentiment\n",
      "0  at first gumagana cya..pero pagnalowbat cya nd...          1\n",
      "1  grabi pangalawa ko ng order sa shapee pero pur...          1\n",
      "2  2l gray/black order ko. bakit 850ml lang po pi...          1\n",
      "3  walang silbing product.. bwesit. di gumagana d...          1\n",
      "4  d po maganda naman po yung neck fan, pero po n...          4\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('dataset/SentiTaglish_ProductsAndServices.csv')\n",
    "print(\"Original dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ac2df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review\n",
      "0  at first gumagana cya..pero pagnalowbat cya nd...\n",
      "1  grabi pangalawa ko ng order sa shapee pero pur...\n",
      "2  2l gray/black order ko. bakit 850ml lang po pi...\n",
      "3  walang silbing product.. bwesit. di gumagana d...\n",
      "4  d po maganda naman po yung neck fan, pero po n...\n"
     ]
    }
   ],
   "source": [
    "# Drop the sentiment column\n",
    "reviews_df = df.drop(columns=['sentiment'])\n",
    "print(reviews_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec261ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = reviews_df['review'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01e67728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stopwords\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "# Basic Tagalog/Filipino stopwords (expand this list if needed)\n",
    "tagalog_stopwords = {\n",
    "    'ako', 'ikaw', 'siya', 'tayo', 'kami', 'kayo', 'sila',\n",
    "    'ang', 'ng', 'sa', 'para', 'ay', 'na', 'nang', 'at', 'pero', 'kung', 'kasi', 'dahil',\n",
    "    'hindi', 'oo', 'huwag', 'wala', 'meron', 'may', 'niya', 'rin', 'din', 'ito', 'iyan',\n",
    "    'iyon', 'doon', 'dito', 'kaya', 'lamang', 'lang', 'lng', 'mga',\n",
    "    'ko', 'pa', 'po', 'sya', 'xa', 'yung', 'ung', 'un', 'naman', 'nmn', 'nman',\n",
    "    'kaso', 'ok', 'okay', 'ganda', 'di', 'nyo', 'nila', 'muna',\n",
    "    'sana', 'bago', 'nga', 'kc', 'tnx', 'salamat', 'mag', 'nag',\n",
    "    'sna', 'nasa', 'mo', 'nya', 'isa'\n",
    "}\n",
    "\n",
    "combined_stopwords = set(english_stopwords).union(tagalog_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "215e29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_data(documents):\n",
    "    return [\n",
    "        [word for word in simple_preprocess(str(doc)) if word not in combined_stopwords]\n",
    "        for doc in documents\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3c0885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the documents\n",
    "processed_texts = preprocess_data(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bfd68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary and corpus\n",
    "id2word = corpora.Dictionary(processed_texts)\n",
    "corpus = [id2word.doc2bow(text) for text in processed_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a38676bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train the LDA model\n",
    "num_topics = 10\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=num_topics,\n",
    "    random_state=42,\n",
    "    passes=10,\n",
    "    alpha='auto',\n",
    "    per_word_topics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "195f2b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics found by LDA:\n",
      "[(0,\n",
      "  '0.044*\"maganda\" + 0.034*\"dumating\" + 0.032*\"order\" + 0.029*\"size\" + '\n",
      "  '0.024*\"seller\" + 0.021*\"quality\" + 0.016*\"good\" + 0.014*\"color\" + '\n",
      "  '0.014*\"maliit\" + 0.013*\"thank\"'),\n",
      " (1,\n",
      "  '0.073*\"seller\" + 0.062*\"thank\" + 0.027*\"order\" + 0.025*\"good\" + '\n",
      "  '0.022*\"item\" + 0.017*\"thanks\" + 0.016*\"rider\" + 0.015*\"shopee\" + '\n",
      "  '0.014*\"ulit\" + 0.014*\"quality\"'),\n",
      " (2,\n",
      "  '0.024*\"makapal\" + 0.018*\"sobrang\" + 0.015*\"overall\" + 0.015*\"condition\" + '\n",
      "  '0.014*\"talaga\" + 0.010*\"excellent\" + 0.009*\"smooth\" + 0.009*\"quality\" + '\n",
      "  '0.009*\"masikip\" + 0.009*\"ka\"'),\n",
      " (3,\n",
      "  '0.022*\"order\" + 0.016*\"kulang\" + 0.015*\"item\" + 0.013*\"tapos\" + 0.011*\"iba\" '\n",
      "  '+ 0.011*\"sira\" + 0.010*\"isang\" + 0.009*\"wag\" + 0.009*\"sayang\" + '\n",
      "  '0.009*\"pinadala\"'),\n",
      " (4,\n",
      "  '0.020*\"pag\" + 0.014*\"pwede\" + 0.014*\"maganda\" + 0.011*\"gamitin\" + '\n",
      "  '0.011*\"gumagana\" + 0.010*\"price\" + 0.010*\"nung\" + 0.010*\"parang\" + '\n",
      "  '0.009*\"pang\" + 0.009*\"talaga\"'),\n",
      " (5,\n",
      "  '0.026*\"amoy\" + 0.013*\"love\" + 0.012*\"packaged\" + 0.012*\"good\" + '\n",
      "  '0.011*\"parang\" + 0.011*\"like\" + 0.009*\"mabango\" + 0.007*\"medyo\" + '\n",
      "  '0.007*\"well\" + 0.007*\"pag\"'),\n",
      " (6,\n",
      "  '0.021*\"blue\" + 0.014*\"godbless\" + 0.014*\"color\" + 0.011*\"dumating\" + '\n",
      "  '0.011*\"item\" + 0.011*\"black\" + 0.010*\"soon\" + 0.009*\"seller\" + 0.009*\"best\" '\n",
      "  '+ 0.008*\"order\"'),\n",
      " (7,\n",
      "  '0.038*\"sulit\" + 0.018*\"service\" + 0.013*\"hangin\" + 0.012*\"fan\" + '\n",
      "  '0.011*\"price\" + 0.011*\"malakas\" + 0.010*\"recommended\" + 0.010*\"product\" + '\n",
      "  '0.010*\"worth\" + 0.010*\"mouse\"'),\n",
      " (8,\n",
      "  '0.021*\"surely\" + 0.016*\"perfect\" + 0.015*\"think\" + 0.012*\"school\" + '\n",
      "  '0.010*\"phone\" + 0.009*\"cm\" + 0.008*\"back\" + 0.007*\"connect\" + 0.007*\"tska\" '\n",
      "  '+ 0.007*\"day\"'),\n",
      " (9,\n",
      "  '0.027*\"super\" + 0.021*\"affordable\" + 0.019*\"legit\" + 0.018*\"uulitin\" + '\n",
      "  '0.018*\"thankyou\" + 0.017*\"food\" + 0.017*\"bilis\" + 0.016*\"maganda\" + '\n",
      "  '0.015*\"matagal\" + 0.015*\"nagdeliver\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the topics\n",
    "print(\"\\nTopics found by LDA:\")\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "062303dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score: 0.38468656343648344\n"
     ]
    }
   ],
   "source": [
    "# Compute coherence score\n",
    "coherence_model_lda = CoherenceModel(\n",
    "    model=lda_model,\n",
    "    texts=processed_texts,\n",
    "    dictionary=id2word,\n",
    "    coherence='c_v'\n",
    ")\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score:', coherence_lda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
